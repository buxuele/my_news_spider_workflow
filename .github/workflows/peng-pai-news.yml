# 工作流名称，在 GitHub Actions 界面显示
name: 爬虫自动化

# 触发条件：每5分钟运行一次，或手动触发
on:
  schedule:
    - cron: '*/5 * * * *'  # 每5分钟触发
  workflow_dispatch:      # 支持手动触发，方便测试

# 定义任务
jobs:
  run-crawler:
    # 使用最新的 Ubuntu 环境
    runs-on: ubuntu-latest

    # 执行步骤
    steps:
      # 步骤1：拉取仓库代码
      - name: 拉取代码
        uses: actions/checkout@v4

      # 步骤2：设置 Python 环境
      - name: 配置 Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'  # 使用 Python 3.9

      # 步骤3：安装依赖（如果有 requirements.txt）
      - name: 安装依赖
        run: |
          if [ -f requirements.txt ]; then
            pip3 install -r requirements.txt
          fi

      # 步骤4：打印当前时间，方便调试
      - name: 打印运行时间
        run: echo "now is >>> $(date)"

      # 步骤5：运行爬虫脚本
      - name: 运行爬虫
        run: python3 news_spider/peng_pai_02.py

      # 步骤6：提交生成的 CSV 文件到仓库
      - name: 提交 CSV 文件
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add csv_data/peng_pai_news_*.csv
          git commit -m "添加新爬虫数据: peng_pai_news_$(date +%Y%m%d_%H%M%S).csv" || echo "没有新文件提交"
          git push
        # 仅当爬虫运行成功时执行
        if: success()